{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08b213f-5da6-48b2-b0a2-d75998f5e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import torchaudio\n",
    "from spauq.core.metrics import spauq_eval\n",
    "import zlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bb9b35-475c-4efc-a1c7-8f7785abd3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb43b2aaeb4d4e2589e5903da4f50807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8503c61db28447b4963acb4b1892e3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"danjacobellis/aria_ea_audio_preprocessed\",split='validation').with_format(\"torch\").select(range(0,1200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df844d0-e276-4b03-a208-6c997a06a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3(sample):\n",
    "    fs=48000\n",
    "    audio = sample['audio'].permute(1,0)\n",
    "    config = torchaudio.io.CodecConfig(qscale=9)\n",
    "    size_bytes = []\n",
    "    recovered = []\n",
    "    for channel in audio:\n",
    "        with BytesIO() as f:\n",
    "            torchaudio.save(f, channel.unsqueeze(0), format=\"mp3\", sample_rate=fs, compression=config)\n",
    "            size_bytes.append(len(f.getvalue()))\n",
    "            f.seek(0)\n",
    "            recovered.append(torchaudio.load(f,format=\"mp3\")[0])\n",
    "    recovered = torch.cat(recovered)\n",
    "    eval_output = spauq_eval(reference=audio,estimate=recovered,fs=fs)\n",
    "    sample['mp3_SSR'] = eval_output['SSR']\n",
    "    sample['mp3_SRR'] = eval_output['SRR']\n",
    "    sample['mp3_cr'] = 3*audio.numel()/sum(size_bytes) # 24 bit audio\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a0870c-701a-4a60-b39c-468666e79cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4656a6f6f2c47a2b9bf3f30115af592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/spauq/core/preprocessing.py:325: UserWarning: No forgive_mode specified, defaulting to `none`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abe3c77-1c33-45bb-b5f2-cc6cd7073211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dance.audio import RateDistortionAutoEncoder\n",
    "device = \"cuda\"\n",
    "dance_model = RateDistortionAutoEncoder()\n",
    "checkpoint = torch.load(\"dance/audio_stage2_2e.pth\")\n",
    "dance_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "dance_model = dance_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38176de5-a69c-4a12-ae0e-b6d88692621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dance(sample):\n",
    "    fs=48000\n",
    "    audio = sample['audio'].permute(1,0)\n",
    "    with torch.no_grad():\n",
    "        compressed = dance_model.encode(audio.unsqueeze(0).cuda()).round().to(torch.int8).cpu().numpy()\n",
    "        original_shape = compressed.shape\n",
    "        compressed = zlib.compress(compressed.tobytes(),level=9)\n",
    "        size_bytes = len(compressed)\n",
    "        recovered = zlib.decompress(compressed)\n",
    "        recovered = np.frombuffer(recovered, dtype=np.int8)\n",
    "        recovered = recovered.reshape(original_shape)\n",
    "        recovered = torch.tensor(recovered).to(torch.float).cuda()\n",
    "        recovered = dance_model.decode(recovered).cpu()[0]\n",
    "        eval_output = spauq_eval(reference=audio,estimate=recovered,fs=fs)\n",
    "        sample['dance_SSR'] = eval_output['SSR']\n",
    "        sample['dance_SRR'] = eval_output['SRR']\n",
    "        sample['dance_cr'] = 3*audio.numel()/size_bytes# 24 bit audio\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d02a25b-a13a-4cc6-8d5a-8492dce3117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcde6b1bd8342e0800bb3a71a7f1c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/spauq/core/preprocessing.py:325: UserWarning: No forgive_mode specified, defaulting to `none`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(dance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ff6c64-d4a0-416a-8dee-3d8534848717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp3_SSR: 19.104087829589844 (mean)\n",
      "mp3_SSR: 18.616052627563477 (median) \n",
      "mp3_SRR: 7.199904441833496 (mean)\n",
      "mp3_SRR: 7.280512809753418 (median) \n",
      "mp3_cr: 26.87841796875 (mean)\n",
      "mp3_cr: 26.595407485961914 (median) \n",
      "dance_SSR: 8.892154693603516 (mean)\n",
      "dance_SSR: 6.188332557678223 (median) \n",
      "dance_SRR: -4.051605701446533 (mean)\n",
      "dance_SRR: 0.4496538043022156 (median) \n",
      "dance_cr: 1599.774169921875 (mean)\n",
      "dance_cr: 154.68093872070312 (median) \n"
     ]
    }
   ],
   "source": [
    "metrics = dataset.remove_columns(['audio','seq_name'])\n",
    "for m in metrics.features:\n",
    "    print(f\"{m}: {metrics[m].mean()} (mean)\")\n",
    "    print(f\"{m}: {metrics[m].median()} (median) \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
